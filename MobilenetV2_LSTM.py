# -*- coding: utf-8 -*-
"""Frame_by_frame.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gbxG7M71baDkHqbKiQQU-vB2-X16AScy
"""

# Mount Google Drive to access your dataset
from google.colab import drive
drive.mount('/content/drive')

import os
import numpy as np
import cv2
from sklearn.model_selection import train_test_split
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input, MobileNetV2
from tensorflow.keras import Input, Model
from tensorflow.keras.layers import TimeDistributed, LSTM, Dense, Dropout, GlobalAveragePooling2D
from tensorflow.keras.optimizers import Adam
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score

# Parameters
SEQUENCE_LENGTH = 10
IMG_SIZE = (224, 224)
BATCH_SIZE = 8
EPOCHS = 10
DATASET_PATH = '/content/drive/MyDrive/action_data'  # Change to your folder path in Drive

# Function to load video frames
def load_video_frames(video_path, sequence_length=SEQUENCE_LENGTH, frame_size=IMG_SIZE):
    cap = cv2.VideoCapture(video_path)
    frames = []
    count = 0
    while count < sequence_length:
        ret, frame = cap.read()
        if not ret:
            break
        frame = cv2.resize(frame, frame_size)
        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        frames.append(frame)
        count += 1
    cap.release()
    # Pad with black frames if less
    if len(frames) < sequence_length:
        padding = [np.zeros((frame_size[0], frame_size[1], 3), dtype=np.uint8)] * (sequence_length - len(frames))
        frames.extend(padding)
    frames = np.array(frames)
    return frames

# Load dataset from folders and assign labels
def load_dataset(data_dir, classes=['punch', 'non_punch']):
    X = []
    y = []
    for label, cls in enumerate(classes):
        cls_path = os.path.join(data_dir, cls)
        for file in os.listdir(cls_path):
            if file.lower().endswith(('.mp4', '.avi', '.mov', '.mkv')):
                video_path = os.path.join(cls_path, file)
                frames = load_video_frames(video_path)
                X.append(frames)
                y.append(label)
    return np.array(X), np.array(y)

# Load all data
X, y = load_dataset(DATASET_PATH)

# Split data: 70% train, 15% val, 15% test with stratification for classes
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)

print(f"Train samples: {len(X_train)}, Val samples: {len(X_val)}, Test samples: {len(X_test)}")

# Preprocess frames with MobileNetV2 preprocessing function
def preprocess_sequences(sequences):
    preprocessed = np.empty_like(sequences, dtype=np.float32)
    for i, seq in enumerate(sequences):
        preprocessed[i] = preprocess_input(seq.astype(np.float32))
    return preprocessed

X_train = preprocess_sequences(X_train)
X_val = preprocess_sequences(X_val)
X_test = preprocess_sequences(X_test)

# Build model with TimeDistributed MobileNetV2 + LSTM
input_shape = (SEQUENCE_LENGTH, IMG_SIZE[0], IMG_SIZE[1], 3)
inputs = Input(shape=input_shape)

base_cnn = MobileNetV2(weights='imagenet', include_top=False, input_shape=IMG_SIZE + (3,))
base_cnn.trainable = False

x = TimeDistributed(base_cnn)(inputs)
x = TimeDistributed(GlobalAveragePooling2D())(x)
x = LSTM(64, return_sequences=True)(x)
x = LSTM(128)(x)
x = Dense(64, activation='relu')(x)
x = Dropout(0.3)(x)
outputs = Dense(len(np.unique(y)), activation='softmax')(x)

model = Model(inputs, outputs)
model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])

model.summary()

# Train model
history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=EPOCHS, batch_size=BATCH_SIZE)

# Evaluate model on test set
y_pred_prob = model.predict(X_test)
y_pred = np.argmax(y_pred_prob, axis=1)

print(f"Test Accuracy: {accuracy_score(y_test, y_pred):.4f}")
print(f"Precision (macro): {precision_score(y_test, y_pred, average='macro'):.4f}")
print(f"Recall (macro): {recall_score(y_test, y_pred, average='macro'):.4f}")
print(f"F1 Score (macro): {f1_score(y_test, y_pred, average='macro'):.4f}")
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred, target_names=['punch', 'non_punch']))

