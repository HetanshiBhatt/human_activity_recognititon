# -*- coding: utf-8 -*-
"""Frame_by_frame.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gbxG7M71baDkHqbKiQQU-vB2-X16AScy
"""

# Mount Google Drive to access your dataset
from google.colab import drive
drive.mount('/content/drive')

import os
import numpy as np
import cv2
from sklearn.model_selection import train_test_split
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input, MobileNetV2
from tensorflow.keras import Input, Model
from tensorflow.keras.layers import TimeDistributed, LSTM, Dense, Dropout, GlobalAveragePooling2D
from tensorflow.keras.optimizers import Adam
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score

# Parameters
SEQUENCE_LENGTH = 30
IMG_SIZE = (224, 224)
BATCH_SIZE = 8
EPOCHS = 50
DATASET_PATH = '/content/drive/MyDrive/action_data'  # Change to your folder path in Drive

# Load base MobileNetV2 model without top layers to extract features per frame
base_cnn = MobileNetV2(weights='imagenet', include_top=False, pooling='avg', input_shape=(224,224,3))
# We will use this to extract feature vectors per frame

def extract_frame_features(video_path, sequence_length=SEQUENCE_LENGTH, frame_size=IMG_SIZE):
    cap = cv2.VideoCapture(video_path)
    features = []
    count = 0

    while count < sequence_length:
        ret, frame = cap.read()
        if not ret:
            break
        frame = cv2.resize(frame, frame_size)
        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        frame = preprocess_input(frame.astype(np.float32))  # Preprocess for MobileNetV2

        frame = np.expand_dims(frame, axis=0)  # Shape (1,224,224,3)
        feature_vector = base_cnn.predict(frame, verbose=0)  # Shape (1, 1280)
        features.append(feature_vector[0])

        count += 1

    cap.release()

    # Pad sequence with zeros if video is short
    if len(features) < sequence_length:
        padding = [np.zeros((base_cnn.output_shape[1],), dtype=np.float32)] * (sequence_length - len(features))
        features.extend(padding)

    return np.array(features)  # Shape (sequence_length, feature_dim)


def load_dataset(data_dir, classes=['punch', 'non_punch']):
    X = []
    y = []
    for label, cls in enumerate(classes):
        cls_path = os.path.join(data_dir, cls)
        for file in os.listdir(cls_path):
            if file.lower().endswith(('.mp4', '.avi', '.mov', '.mkv')):
                video_path = os.path.join(cls_path, file)
                features_seq = extract_frame_features(video_path)
                X.append(features_seq)
                y.append(label)
    return np.array(X), np.array(y)

# Load all data
X, y = load_dataset(DATASET_PATH)

# Split data: 70% train, 15% val, 15% test with stratification for classes
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)

print(f"Train samples: {len(X_train)}, Val samples: {len(X_val)}, Test samples: {len(X_test)}")

# Preprocess frames with MobileNetV2 preprocessing function
def preprocess_sequences(sequences):
    preprocessed = np.empty_like(sequences, dtype=np.float32)
    for i, seq in enumerate(sequences):
        preprocessed[i] = preprocess_input(seq.astype(np.float32))
    return preprocessed

X_train = preprocess_sequences(X_train)
X_val = preprocess_sequences(X_val)
X_test = preprocess_sequences(X_test)

# Build model with TimeDistributed MobileNetV2 + LSTM
input_shape = (SEQUENCE_LENGTH, IMG_SIZE[0], IMG_SIZE[1], 3)
inputs = Input(shape=input_shape)

base_cnn = MobileNetV2(weights='imagenet', include_top=False, input_shape=IMG_SIZE + (3,))
base_cnn.trainable = False

x = TimeDistributed(base_cnn)(inputs)
x = TimeDistributed(GlobalAveragePooling2D())(x)
x = LSTM(64, return_sequences=True)(x)
x = LSTM(128)(x)
x = Dense(64, activation='relu')(x)
x = Dropout(0.3)(x)
outputs = Dense(len(np.unique(y)), activation='softmax')(x)

model = Model(inputs, outputs)
model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])

model.summary()

# Train model
history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=EPOCHS, batch_size=BATCH_SIZE)

# Evaluate model on test set
y_pred_prob = model.predict(X_test)
y_pred = np.argmax(y_pred_prob, axis=1)

print(f"Test Accuracy: {accuracy_score(y_test, y_pred):.4f}")
print(f"Precision (macro): {precision_score(y_test, y_pred, average='macro'):.4f}")
print(f"Recall (macro): {recall_score(y_test, y_pred, average='macro'):.4f}")
print(f"F1 Score (macro): {f1_score(y_test, y_pred, average='macro'):.4f}")
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred, target_names=['punch', 'non_punch']))

"""# **Final Code**"""



# Mount Google Drive to access your dataset
from google.colab import drive
drive.mount('/content/drive')

import os
import numpy as np
import cv2
from sklearn.model_selection import train_test_split
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input, MobileNetV2
from tensorflow.keras import Input, Model
from tensorflow.keras.layers import TimeDistributed, LSTM, Dense, Dropout, GlobalAveragePooling2D
from tensorflow.keras.optimizers import Adam
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score

# Parameters
SEQUENCE_LENGTH = 10  # Updated from 10
IMG_SIZE = (224, 224)
BATCH_SIZE = 8
EPOCHS = 50  # Updated from 10
DATASET_PATH = '/content/drive/MyDrive/action_data'

# Function to load video frames
def load_video_frames(video_path, sequence_length=SEQUENCE_LENGTH, frame_size=IMG_SIZE):
    cap = cv2.VideoCapture(video_path)
    frames = []
    count = 0
    while count < sequence_length:
        ret, frame = cap.read()
        if not ret:
            break
        frame = cv2.resize(frame, frame_size)
        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        frames.append(frame)
        count += 1
    cap.release()
    # Pad with black frames if less
    if len(frames) < sequence_length:
        padding = [np.zeros((frame_size[0], frame_size[1], 3), dtype=np.uint8)] * (sequence_length - len(frames))
        frames.extend(padding)
    frames = np.array(frames)
    return frames

# Load dataset from folders and assign labels
def load_dataset(data_dir, classes=['punch', 'non_punch']):
    X = []
    y = []
    for label, cls in enumerate(classes):
        cls_path = os.path.join(data_dir, cls)
        for file in os.listdir(cls_path):
            if file.lower().endswith(('.mp4', '.avi', '.mov', '.mkv')):
                video_path = os.path.join(cls_path, file)
                frames = load_video_frames(video_path)
                X.append(frames)
                y.append(label)
    return np.array(X), np.array(y)

# Load all data
X, y = load_dataset(DATASET_PATH)

# Split data: 70% train, 15% val, 15% test with stratification for classes
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)

print(f"Train samples: {len(X_train)}, Val samples: {len(X_val)}, Test samples: {len(X_test)}")

# Preprocess frames with MobileNetV2 preprocessing function
def preprocess_sequences(sequences):
    preprocessed = np.empty_like(sequences, dtype=np.float32)
    for i, seq in enumerate(sequences):
        preprocessed[i] = preprocess_input(seq.astype(np.float32))
    return preprocessed

X_train = preprocess_sequences(X_train)
X_val = preprocess_sequences(X_val)
X_test = preprocess_sequences(X_test)

# Build model with TimeDistributed MobileNetV2 + LSTM
input_shape = (SEQUENCE_LENGTH, IMG_SIZE[0], IMG_SIZE[1], 3)
inputs = Input(shape=input_shape)

base_cnn = MobileNetV2(weights='imagenet', include_top=False, input_shape=IMG_SIZE + (3,))
base_cnn.trainable = False

x = TimeDistributed(base_cnn)(inputs)
x = TimeDistributed(GlobalAveragePooling2D())(x)
x = LSTM(64, return_sequences=True)(x)
x = LSTM(128)(x)
x = Dense(64, activation='relu')(x)
x = Dropout(0.3)(x)
outputs = Dense(len(np.unique(y)), activation='softmax')(x)

model = Model(inputs, outputs)
model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])

model.summary()

# Train model
history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=EPOCHS, batch_size=BATCH_SIZE)

from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
import numpy as np

# Predict probabilities and classes on test data
y_pred_prob = model.predict(X_test)
y_pred = np.argmax(y_pred_prob, axis=1)

# Basic metrics
print(f"Test Accuracy: {accuracy_score(y_test, y_pred):.4f}")

print(f"Macro Precision: {precision_score(y_test, y_pred, average='macro'):.4f}")
print(f"Micro Precision: {precision_score(y_test, y_pred, average='micro'):.4f}")

print(f"Macro Recall: {recall_score(y_test, y_pred, average='macro'):.4f}")
print(f"Micro Recall: {recall_score(y_test, y_pred, average='micro'):.4f}")

print(f"Macro F1 Score: {f1_score(y_test, y_pred, average='macro'):.4f}")
print(f"Micro F1 Score: {f1_score(y_test, y_pred, average='micro'):.4f}")

# Confusion matrix
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))

# Classification report
print("Classification Report:")
print(classification_report(y_test, y_pred, target_names=['punch', 'non_punch']))

# ROC-AUC (only for binary classification)
if y_pred_prob.shape[1] == 2:
    print(f"ROC-AUC: {roc_auc_score(y_test, y_pred_prob[:, 1]):.4f}")

import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# Generate confusion matrix from true and predicted labels
cm = confusion_matrix(y_test, y_pred)

# Optionally normalize the confusion matrix for better interpretability
cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]

# Create figure and axis
fig, ax = plt.subplots(figsize=(6, 6))

# Plot normalized confusion matrix with blue colormap
im = ax.imshow(cm_normalized, interpolation='nearest', cmap=plt.cm.Blues)

# Add color bar to show scale
cbar = ax.figure.colorbar(im, ax=ax)
cbar.ax.set_ylabel('Proportion', rotation=-90, va="bottom")

# Set ticks and labels
classes = ['non_punch', 'punch']
ax.set(
    xticks=np.arange(len(classes)),
    yticks=np.arange(len(classes)),
    xticklabels=classes,
    yticklabels=classes,
    ylabel='True Label',
    xlabel='Predicted Label',
    title='Normalized Confusion Matrix'
)

# Rotate x-axis labels for readability
plt.setp(ax.get_xticklabels(), rotation=45, ha="right", rotation_mode="anchor")

# Annotate each cell with counts and percentages
fmt = '.2f'  # format for normalized values
thresh = cm_normalized.max() / 2.

for i in range(cm.shape[0]):
    for j in range(cm.shape[1]):
        count = cm[i, j]
        percent = cm_normalized[i, j]
        ax.text(
            j, i,
            f"{count}\n({percent:{fmt}})",
            ha="center", va="center",
            color="white" if percent > thresh else "black"
        )

fig.tight_layout()
plt.show()

